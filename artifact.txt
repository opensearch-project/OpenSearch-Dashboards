Artifacts

Important

* Asana Board
* AI in OSD Engineering plan
* CoAgent Research

Action Items

Task	Completed	Assignee	Asana	Notes
Research how CoAgent and other things do in app stuff like this and add an appendix section with the details	0	Qingyang(Abby) Hu	https://app.asana.com/1/8442528107068/project/1208669492952159/task/1211128218045638?focus=true


Parent task: https://app.asana.com/1/8442528107068/project/1211083178283712/task/1211086086329350?focus=true
	
Define two-way interaction (the agent can interact with the application) and add it to Appendix A		Qingyang(Abby) Hu		Potentially related:

https://docs.ag-ui.com/concepts/events

 https://docs.ag-ui.com/concepts/state#human-in-the-loop-collaboration
Define tools and add it to Appendix A		Qingyang(Abby) Hu		
Define MCP and add it to Appendix A		Qingyang(Abby) Hu		

Overview

Artifacts are the tangible outputs from interactions with AI assistants in OSD. When users chat with an AI assistant about their data, they often need more than just text responses. They need actual, usable elements they can work with. These artifacts can take many forms: visualizations showing specific trends, saved searches capturing complex query logic, alerts configured to monitor critical thresholds, or even complete dashboards assembled to answer business questions.

This capability transforms how users work with their data in OSD by making the AI assistant a collaborative partner in the data exploration and visualization process. Instead of just advising what might work, the AI agent can actually demonstrate it, allowing users to iterate quickly and focus on insights rather than implementation details.

Requirements

Requirement	Description	Notes
In-chat artifacts	For example Diya has artifacts. 

For OSD, an example in chat artifact it will have the viz in the chat

By default the viz is not saved and the user can modify it. The user can then save it with a manual interaction (potentially could just use the saved objects API)	
Direct modification artifacts	It will be able to modify the dashboard directly without the user’s manual interaction and add the viz automatically. 

But similar to Cline where the user can confirm if they want the change saved or not.

We could also have a checkbox to save automatically without user confirmation	CoAgent
Ability to revert changes	If we want to modify or keep working on a visualization in context then users might older version or decide they want to go down a previous state because the branch they are on is too far off track	
Support versions on artifacts	The artifact has a version it would be good to keep that context and allow the user to restore to an older version. 	How long do we keep track of that version?

How many artifacts do we keep in memory for example what if a single chat context has 2 visualizations that the user is creating how do let the user switch between different versions of different components
Framework 	Flexiable for plugin developers to add on to this framework without hardcoding logic	

Proposals

Proposal A: Utilize homebrewed services

Agent directly modifying the application

For example, if the agent comes back with a response to directly modify the dashboard to add a visualization. The chat can get that response and then emit an action via the UI actions plugin

* UI actions exposes a global event bus within OSD that allows other plugins to expand the ui capabilities of the application using actions and triggers. 
* Plugins can register actions, they can trigger an action, and use existing triggers and actions for their own use case. 
* Multiple actions can be associated with a single trigger.

Artifact only within chat

For example, if the response comes back with a response to just display a visualization in chat. The Embeddables plugin to create a slot for a widget container. With the capability for the user to modify the visualization and then an option to easily create a saved object and associate it to the dashboard.

* Embeddables are re-usable widgets that can be rendered in any environment or plugin.
* Already used by the dashboard page of OSD [example]. Plugin developers tells us how it should look as an embeddable in the dashboard.
* The chat could do the same with providing a container for plugins to register 
* Embeddables will make it easier to build out the framework vs hardcoding stuff into our repo

TODO: We will need to handle the case where multiple plugins can register something that is relevant to the current context and response. How do we make sure we provide a solution that lets the user decide which is the best option while also defaulting to the response if there is only one embeddable provider

For rendering and other functions,this system can utilize the Expressions plugin alongside Embeddables

* Expressions plugin provides methods to parse and execute expression pipelines while offering registries for developers to incorporate their own functions, types and renderers
* Already used by rendering visualizations within OSD.
* Supports functions via function configuration with arguments and flexible output handling
* Expressions will make it easier to build out the framework vs hardcoding stuff into our repo

History and Reverting

Utilize the Search Source to managed a tree like architecture

* Search source is already a tree so reverting would just be climbing up the tree so we have a reference to the parent node
* It has reference to the parent node which has the query and could store the response
    * Query could be the message from the user/agent will create a child node when a new message is fired
    * Response could be the output of that message (example visualization)

TODO: How do we handle reverting agentic direct updates. Do we need a way for the UI actions to emit that an agent did this action and does that need to keep that in memory for a certain period of time? Historically speaking we might just need have a confirmation button to save it or we can have an automatic save if the user checkboxs something

Proposal B:  New system build natively in OSD

TODO: Look into CoAgents and how it does it and if we can create a new framework?


Proposal C:  Library - CoAgents

OpenSouce package: https://github.com/CopilotKit/CopilotKit

What is CoAgents

CoAgents is a React library that creates a collaborative loop between AI and humans. The AI agent analyzes your current dashboard state, proposes specific improvements, then waits for explicit approval before executing any changes. It's built on state machines that handle workflow transitions and maintain rollback capabilities if something goes wrong.

How It Works

┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Analyze   │───▶│  Propose    │───▶│   Approve   │───▶│   Execute   │
│  Dashboard  │    │  Changes    │    │  Changes    │    │  & Rollback │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
      ▲                                       │                    │
      └───────────────── Back to Start ◀─────┴────────────────────┘


The state machine manages three core phases: analysis (AI examines data patterns), proposal generation (creates specific actionable suggestions), and execution (applies approved changes). Each transition is tracked with automatic rollback capability if errors occur during application.

// AI provides structured proposals
{
  changeType: "add_visualization",
  preview: "<chart preview>",
  confidence: 0.85,
  reasoning: "Detected correlation in time series data"
}

// Rollback stack automatically maintained
previousStates = [
  { timestamp: "10:30", snapshot: dashboardState },
  { timestamp: "10:25", snapshot: previousState }
];

Integration with OSD Architecture

CoAgents works as an orchestration layer that leverages OSD's existing infrastructure without replacing it. UI Actions handle the event-driven communication between dashboard components. SearchSource manages data queries and their hierarchical relationships. CoAgents adds intelligent automation on top that analyzes SearchSource data, generates suggestions through your AI service, and executes approved changes through UI Actions.
The key advantage is that CoAgents uses your existing OSD plugin services (visualization registry, saved objects client, dashboard API) but adds the AI workflow layer with human oversight that none of these provide individually.

// How systems interact
CoAgents.analyze(searchSource.getData()) 
  .callYourAI() 
  .generateSuggestions() 
  .waitForApproval() 
  .execute(uiActions.trigger)
  .updateSearchSource()

Complete Workflow Example

Here's how a typical chat-to-dashboard interaction flows through the entire system:

User types: "Show me error trends over the last week"
↓
CoAgents captures message + current dashboard state
↓  
Calls your custom AI API with context (data fields, existing panels, user intent)
↓
Your AI service analyzes and returns structured suggestions
↓
CoAgents shows approval UI with previews and reasoning
↓
User reviews and clicks "Apply Selected Changes"
↓
CoAgents saves current state to rollback stack
↓
Executes via uiActions.trigger('DASHBOARD_ADD_PANEL', config)
↓
Dashboard components listen to UI Actions and update
↓
SearchSource creates queries for new panels and refreshes data

Pros

* Human-in-the-loop workflows already built vs months of custom development.
* Handles error recovery, rollbacks, and edge cases out of the box.
* Works with existing UI Actions/SearchSource without architectural changes.
*  Use any backend API while getting workflow orchestration for free.

Cons

*  Another library to maintain and security review, go thru appsec
* Workflow history doesn't persist across sessions.
* May not fit highly custom workflow requirements.

More implementation details could be found in Appendix C.


Proposal D:  ???

TODO: Leaving room if you want to add anything if you have another idea Qingyang(Abby) Hu

Appendix

Appendix A:  Glossary

Term	Definition
	
	
	
	
	

Appendix B:  What are AI artifacts?

Unspecific to OSD and this project

AI artifacts are outputs from AI systems, ranging from simple text or image files to complex trained models, code, or even unexpected behaviors and errors. They serve as digital products that result from training or processing with AI tools, such as datasets, models, logs, and environmental configurations. Analyzing these artifacts helps developers understand, debug, and improve AI systems, leading to more accurate, fair, and transparent AI.

Appendix C: CoAgents and how to use it in OSD


State Machine: A workflow system that tracks where you are in a process (analyzing → proposing → approving → executing) and handles transitions between steps.
Human-in-the-Loop: AI suggests actions but waits for human approval before executing them.
UI Actions: OSD's event bus system where components communicate by emitting and listening to events.
SearchSource: OSD's data layer that manages queries, aggregations, and data fetching in a tree structure.


What is CoAgents

CoAgents is a React library that creates a collaborative loop between AI and humans. The AI agent analyzes your current dashboard state, proposes specific improvements, then waits for explicit approval before executing any changes. It's built on state machines that handle workflow transitions and maintain rollback capabilities if something goes wrong.

// The basic flow
AI: "I see time-series data, should I add a line chart?"
Human: "Yes, apply it" 
AI: *adds chart with automatic rollback if it breaks*



The framework provides structured proposals with reasoning, confidence scores, and visual previews. Each suggestion includes enough context for users to make informed decisions before applying changes to their dashboard.

How It Works

┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Analyze   │───▶│  Propose    │───▶│   Approve   │───▶│   Execute   │
│  Dashboard  │    │  Changes    │    │  Changes    │    │  & Rollback │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
      ▲                                       │                    │
      └───────────────── Back to Start ◀─────┴────────────────────┘



The state machine manages three core phases: analysis (AI examines data patterns), proposal generation (creates specific actionable suggestions), and execution (applies approved changes). Each transition is tracked with automatic rollback capability if errors occur during application.

{
  state: "awaiting_approval",
  proposals: [{
    action: "add_line_chart",
    reasoning: "Your data shows trends over time", 
    confidence: 0.9,
    affectedPanels: ["panel-123"]
  }]
}



The workflow maintains a rollback stack in browser memory, typically storing 5-10 previous states. This allows instant undo operations without backend complexity.

Integration with OSD Architecture

CoAgents works as an orchestration layer that leverages OSD's existing infrastructure without replacing it. UI Actions handle the event-driven communication between dashboard components. SearchSource manages data queries and their hierarchical relationships. CoAgents adds intelligent automation on top that analyzes SearchSource data, generates suggestions through your AI service, and executes approved changes through UI Actions.
The key advantage is that CoAgents uses your existing OSD plugin services (visualization registry, saved objects client, dashboard API) but adds the AI workflow layer with human oversight that none of these provide individually.

// How systems interact
CoAgents.analyze(searchSource.getData()) 
  .callYourAI() 
  .generateSuggestions() 
  .waitForApproval() 
  .execute(uiActions.trigger)
  .updateSearchSource()




Complete Workflow Example

Here's how a typical chat-to-dashboard interaction flows through the entire system:

User types: "Show me error trends over the last week"
↓
CoAgents captures message + current dashboard state
↓  
Calls your custom AI API with context (data fields, existing panels, user intent)
↓
Your AI service analyzes and returns structured suggestions
↓
CoAgents shows approval UI with previews and reasoning
↓
User reviews and clicks "Apply Selected Changes"
↓
CoAgents saves current state to rollback stack
↓
Executes via uiActions.trigger('DASHBOARD_ADD_PANEL', config)
↓
Dashboard components listen to UI Actions and update
↓
SearchSource creates queries for new panels and refreshes data




// Frontend chat integration
async handleUserMessage(message) {
  const currentState = {
    panels: dashboard.getAllPanels(),
    indexPatterns: searchSource.getIndexPatterns(),
    timeRange: timeFilter.getTime()
  };
  
  // Your AI API call
  const suggestions = await aiService.analyze({
    userIntent: message,
    dashboardContext: currentState
  });
  
  coAgents.showProposals(suggestions);
}

// Approval execution
onUserApproval(selectedSuggestions) {
  selectedSuggestions.forEach(suggestion => {
    uiActions.trigger('ADD_PANEL', {
      type: suggestion.visType,
      config: suggestion.panelConfig,
      position: suggestion.layout
    });
  });
}



Your AI service receives rich context about the current dashboard state and returns actionable suggestions. CoAgents handles the approval workflow and integrates the approved changes back into OSD's native systems.

Response Format

CoAgents structures responses as JSON objects that OSD components can directly consume:

{
  // Current workflow phase
  state: "awaiting_approval", 
  
  // AI-generated suggestions
  proposals: [{
    // Unique identifier for tracking
    id: "suggestion-1",
    // Type of dashboard modification
    type: "add_visualization",
    // Complete OSD panel configuration
    config: { 
      visType: "line", 
      params: { 
        field: "@timestamp",
        interval: "auto" 
      }
    },
    // Human-readable explanation
    reasoning: "Time series pattern detected in error logs",
    // AI model confidence score
    confidence: 0.87,
    // Base64 encoded preview image
    preview: "data:image/png;base64,iVBOR...",
    // Which existing panels this affects
    affectedPanels: ["panel-456"]
  }],
  
  // Whether undo operations are available
  canRollback: true,
  // Frontend-stored previous states
  rollbackStack: ["state-1", "state-2"],
  // Optional auto-apply for high confidence changes
  autoApproveThreshold: 0.9
}



Each proposal contains complete configuration data that can be directly applied to OSD's dashboard API, along with human-readable context for informed decision making.

FAQ

Q: Why use CoAgents if I'm building my own backend API anyway?
A: CoAgents doesn't replace your backend - it adds the AI decision-making and approval workflow on top. Your AI service handles data analysis and suggestion generation, CoAgents handles the human approval flow, state management, and rollback capabilities. It saves you from building complex workflow orchestration, approval UIs, and undo systems from scratch.

Q: Where is the rollback history stored?
A: Frontend browser memory. Your OSD backend only sees final approved changes, keeping your saved objects clean. The rollback stack typically maintains 5-10 previous states before auto-cleanup.

Q: Can I use my own AI service instead of OpenAI?
A: Yes, completely configurable. CoAgents is AI-service agnostic - point it to any API that can analyze dashboard context
 and return structured suggestions. Could be your own ML models, external APIs, or hybrid approaches.

Q: How is this different from OSD UI Actions alone?
A: UI Actions are the communication mechanism (how components talk to each other). CoAgents is the intelligence layer (what changes to make and when). It analyzes data through SearchSource, generates suggestions via your AI service, manages human approval, then executes through UI Actions.

Q: What if the AI suggests something wrong?
A: That's the core value of human-in-the-loop design. You see detailed previews and reasoning before approval, can reject individual suggestions, and instantly rollback any applied changes. The system prioritizes safety over automation.

Q: How does this work with OSD's plugin system?
A: CoAgents integrates as a standard OSD plugin that extends existing dashboard functionality. It registers with your plugin's setup lifecycle, uses your visualization registry and saved objects client, and follows OSD's component patterns. No architectural changes needed.

Q: What happens if CoAgents crashes during execution?
A: The state machine handles error recovery automatically. If execution fails partway through, it triggers rollback to the last known good state. All changes are atomic operations tracked in the rollback stack.
